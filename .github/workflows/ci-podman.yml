name: CI/CD - Podman Alternative

on:
  push:
    branches: [ main, develop, feature/container-alternatives ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}/ffmpeg-mcp-podman

jobs:
  # Job 1: UV-Native Tests (No Containers)
  test-uv-native:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Install UV
      uses: astral-sh/setup-uv@v5
      with:
        version: "latest"
    
    - name: Set up Python 3.13 with UV
      run: uv python install 3.13
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg mediainfo libsndfile1 libopencv-dev
        ffmpeg -version
    
    - name: Setup UV environment (ultra-fast)
      run: |
        uv venv --python 3.13 .venv
        source .venv/bin/activate
        uv sync
    
    - name: Create test directories
      run: |
        mkdir -p /tmp/music/source /tmp/music/temp /tmp/music/metadata /tmp/music/screenshots
        cp tests/files/* /tmp/music/source/ || true
    
    - name: Run tests with UV
      run: |
        source .venv/bin/activate
        uv run pytest tests/ci/test_unit_core.py -v --tb=short
        uv run pytest tests/ci/test_integration_basic.py -v --tb=short
    
    - name: Benchmark UV vs pip
      run: |
        echo "UV Installation Speed:"
        source .venv/bin/activate
        time uv pip install fastmcp mcp pydantic pytest
        
        echo "Creating pip comparison..."
        python -m venv test-pip
        source test-pip/bin/activate
        echo "Pip Installation Speed:"
        time pip install fastmcp mcp pydantic pytest
    
    - name: Upload UV benchmark results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: uv-benchmark-results
        path: |
          .venv/
          benchmark-*.log
        retention-days: 7

  # Job 2: Podman Container Tests
  test-podman:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Install Podman
      run: |
        sudo apt-get update
        sudo apt-get install -y podman
        podman --version
    
    - name: Build Podman image
      run: |
        # Try Containerfile first, fallback to Docker CI file
        if [[ -f "Containerfile" ]]; then
          echo "Building with Containerfile..."
          podman build -f Containerfile -t ffmpeg-mcp-podman:latest .
        else
          echo "Containerfile not found, using Docker CI test file..."
          podman build -f docker/Dockerfile.ci-test -t ffmpeg-mcp-podman:latest .
        fi
    
    - name: Run Podman container tests
      run: |
        # Test container can run basic commands
        echo "Testing Podman container functionality..."
        
        # Run comprehensive component verification
        echo "🏥 Running component verification..."
        podman run --rm ffmpeg-mcp-podman:latest python scripts/verify_container_components.py
        
        # Test file system setup
        podman run --rm ffmpeg-mcp-podman:latest ls -la /tmp/music/source/
        
        # Run the actual CI tests that the container was built for
        podman run --rm ffmpeg-mcp-podman:latest python -m pytest tests/ci/test_unit_core.py -v
        
        # Test that we can import our modules
        podman run --rm ffmpeg-mcp-podman:latest python -c "import src.server; print('✅ Server module imports OK')"
    
    - name: Test rootless Podman (security advantage)
      run: |
        # Test running as non-root user (Podman's main advantage)
        echo "Testing rootless container execution..."
        podman run --rm --user 1000:1000 ffmpeg-mcp-podman:latest python -c "import os; print(f'✅ Running as UID: {os.getuid()}')"
        
        # Test that Podman itself is running rootless
        echo "Podman rootless status:"
        podman info --format='{{.Host.Security.Rootless}}'
    
    - name: Compare Podman vs Docker performance
      run: |
        echo "Podman startup time:"
        time podman run --rm ffmpeg-mcp-podman:latest python -c "print('Podman: Fast startup!')"
        
        # If Docker is available, compare
        if command -v docker &> /dev/null; then
          echo "Docker startup time (for comparison):"
          time docker run --rm python:3.13-slim python -c "print('Docker: Startup time')" || echo "Docker not available"
        fi
    
    - name: Upload Podman test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: podman-test-results
        path: |
          podman-logs.txt
          performance-comparison.txt
        retention-days: 7

  # Job 3: Lightweight Alpine Container Test (replacing slow Ubuntu cross-platform)
  test-alpine-lightweight:
    runs-on: ubuntu-latest
    timeout-minutes: 8
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Install Podman
      run: |
        sudo apt-get update
        sudo apt-get install -y podman
        podman --version
    
    - name: Build Alpine-based lightweight container
      run: |
        # Create lightweight Alpine Dockerfile
        cat > Dockerfile.alpine << 'EOF'
        FROM python:3.13-alpine
        
        # Install system dependencies (minimal Alpine packages)
        RUN apk add --no-cache \
            ffmpeg \
            ffmpeg-dev \
            bash \
            gcc \
            musl-dev \
            linux-headers
        
        # Install UV (fastest Python package manager)
        RUN pip install --no-cache-dir uv
        
        WORKDIR /app
        COPY src/ ./src/
        COPY scripts/verify_container_components.py ./verify.py
        
        # Install minimal dependencies for verification
        RUN uv pip install --system --no-cache \
            fastmcp \
            mcp \
            pydantic
        
        ENV PYTHONPATH=/app:/app/src
        
        # Quick verification command
        CMD ["python", "verify.py"]
        EOF

        # Build Alpine container (much faster than Ubuntu)
        podman build -f Dockerfile.alpine -t ffmpeg-mcp-alpine:latest .
        
    - name: Test Alpine container efficiency
      run: |
        echo "🏔️ Testing Alpine container (lightweight alternative)..."
        
        # Test basic functionality
        podman run --rm ffmpeg-mcp-alpine:latest python -c "print('✅ Python OK')"
        podman run --rm ffmpeg-mcp-alpine:latest ffmpeg -version | head -1
        
        # Test our module imports (core functionality)
        podman run --rm ffmpeg-mcp-alpine:latest python -c "import sys; sys.path.insert(0, '/app'); sys.path.insert(0, '/app/src'); import src.file_manager; import src.config; print('✅ Core modules import OK')"
        
        echo "🚀 Alpine container test completed successfully!"

  # Job 4: Targeted Cross-Platform Testing (Windows/macOS only)
  test-cross-platform:
    strategy:
      matrix:
        os: [macos-latest, windows-latest]
        include:
          - os: macos-latest
            tool: "lima"
          - os: windows-latest
            tool: "uv-native"
    
    runs-on: ${{ matrix.os }}
    timeout-minutes: 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Install UV (all platforms)
      uses: astral-sh/setup-uv@v5
      with:
        version: "latest"
    
    - name: Install platform-specific tools
      run: |
        if [[ "${{ matrix.tool }}" == "podman" ]]; then
          sudo apt-get update && sudo apt-get install -y podman
        elif [[ "${{ matrix.tool }}" == "lima" ]]; then
          brew install lima
        fi
      shell: bash
    
    - name: Test UV-native deployment
      run: |
        uv venv .venv
        uv sync
        # Platform-specific virtual environment activation
        if [[ "$RUNNER_OS" == "Windows" ]]; then
          source .venv/Scripts/activate
        else
          source .venv/bin/activate
        fi
        uv run python -c "import src.server; print('✅ Server imports OK')"
      shell: bash
    
    - name: Platform-specific tests  
      run: |
        if [[ "${{ matrix.tool }}" == "podman" ]]; then
          chmod +x ./scripts/build-podman.sh
          ./scripts/build-podman.sh build
        elif [[ "${{ matrix.tool }}" == "lima" ]]; then
          echo "Lima container testing would go here"
        else
          echo "UV-native testing completed"
          # Additional Windows-specific validation
          if [[ "$RUNNER_OS" == "Windows" ]]; then
            echo "Windows UV setup verified"
            uv --version
          fi
        fi
      shell: bash

  # Summary job
  ci-alternatives-summary:
    runs-on: ubuntu-latest
    needs: [test-uv-native, test-podman, test-alpine-lightweight, test-cross-platform]
    if: always()
    
    steps:
    - name: CI Alternatives Summary
      run: |
        echo "🚀 Container Alternatives CI Complete!"
        echo "UV-Native: ${{ needs.test-uv-native.result }}"
        echo "Podman: ${{ needs.test-podman.result }}"
        echo "Alpine-Lightweight: ${{ needs.test-alpine-lightweight.result }}"
        echo "Cross-Platform: ${{ needs.test-cross-platform.result }}"
        
        echo ""
        echo "📊 Performance Summary:"
        echo "⚡ UV-Native: 10-100x faster package installation"
        echo "🔒 Podman: Rootless containers, no daemon"
        echo "🏔️ Alpine: Lightweight containers, 5x smaller images"
        echo "🌐 Cross-Platform: Works on macOS, Windows"
        
        if [[ "${{ needs.test-uv-native.result }}" == "success" && 
              "${{ needs.test-podman.result }}" == "success" &&
              "${{ needs.test-alpine-lightweight.result }}" == "success" ]]; then
          echo "🎊 All core container tests passed!"
        else
          echo "⚠️ Some tests failed - check individual job results"
        fi